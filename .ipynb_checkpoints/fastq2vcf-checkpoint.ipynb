{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastq2vcf\n",
    "### Tutorial intended to cover the analysis of human NGS data. In particular the processing of fastq files in order to get variants in VCF format. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "Links: \n",
=======
    "Relevant Links: \n",
>>>>>>> beda7fbb5190155ca96a7702217ac28b225ebc1e
    "\n",
    "[https://jupyter.org/](https://jupyter.org/)  \n",
    "[https://pandas.pydata.org/](https://pandas.pydata.org/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fastq Downloading\n",
    "\n",
    "We are going to use public data from the Simons Genomes Diversity Project ([SGDP](https://reichdata.hms.harvard.edu/pub/datasets/sgdp/)). Specifically 7 selected genomes from each 'Region' included in the dataset. The SGDP Project ID in ENA repository is [PRJEB9586](https://www.ebi.ac.uk/ena/browser/view/PRJEB9586).\n",
    "\n",
    "The code below fetches partial fastq files (2 million paired-end reads per individual) coming from genomes of the 7 different regions defined in the SGDP (CentralAsiaSiberia, Africa, EastAsia, WestEurasia, America, SouthAsia and Oceania). The reduction in reads per sample is to speed up the analysis but the code can be easily modified to get and work on complete genomes.\n",
    "\n",
    "[Here](https://en.wikipedia.org/wiki/FASTQ_format) and [here](https://support.illumina.com/bulletins/2016/04/fastq-files-explained.html) links to the description and explanation of the FASTQ format.\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 1,
>>>>>>> beda7fbb5190155ca96a7702217ac28b225ebc1e
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Dowloading fastq files for sample: LP6005443-DNA_B04\n",
      "__fastq  file already present__\n",
      "__fastq  file already present__\n",
      "Dowloading fastq files for sample: LP6005441-DNA_A08\n",
      "__fastq  file already present__\n",
      "__fastq  file already present__\n",
      "Dowloading fastq files for sample: LP6005441-DNA_B09\n",
      "__fastq  file already present__\n",
      "__fastq  file already present__\n",
      "Dowloading fastq files for sample: LP6005441-DNA_G09\n",
      "__fastq  file already present__\n",
      "__fastq  file already present__\n",
      "Dowloading fastq files for sample: LP6005519-DNA_G02\n",
      "__fastq  file already present__\n",
      "__fastq  file already present__\n",
      "Dowloading fastq files for sample: LP6005442-DNA_B12\n",
      "__fastq  file already present__\n",
      "__fastq  file already present__\n",
      "Dowloading fastq files for sample: LP6005443-DNA_F08\n",
      "__fastq  file already present__\n",
      "__fastq  file already present__\n"
=======
      "Dowloading fastq partial files for sample: LP6005443-DNA_B04\n",
      "__fastq 1 file already present__\n",
      "__fastq 2 file already present__\n",
      "Dowloading fastq partial files for sample: LP6005441-DNA_A08\n",
      "__fastq 1 file already present__\n",
      "__fastq 2 file already present__\n",
      "Dowloading fastq partial files for sample: LP6005441-DNA_B09\n",
      "__fastq 1 file already present__\n",
      "__fastq 2 file already present__\n",
      "Dowloading fastq partial files for sample: LP6005441-DNA_G09\n",
      "__fastq 1 file already present__\n",
      "__fastq 2 file already present__\n",
      "Dowloading fastq partial files for sample: LP6005519-DNA_G02\n",
      "__fastq 1 file already present__\n",
      "__fastq 2 file already present__\n",
      "Dowloading fastq partial files for sample: LP6005442-DNA_B12\n",
      "__fastq 1 file already present__\n",
      "__fastq 2 file already present__\n",
      "Dowloading fastq partial files for sample: LP6005443-DNA_F08\n",
      "__fastq 1 file already present__\n",
      "__fastq 2 file already present__\n"
>>>>>>> beda7fbb5190155ca96a7702217ac28b225ebc1e
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "SGDP_ENA_PID = 'PRJEB9586'\n",
    "ENA_URL = 'https://www.ebi.ac.uk/ena/data/warehouse/filereport?accession=' + SGDP_ENA_PID + '&result=read_run'\n",
    "metadata_URL = 'https://sharehost.hms.harvard.edu/genetics/reich_lab/sgdp/SGDP_metadata.279public.21signedLetter.samples.txt'\n",
    "\n",
    "download_table = pd.read_csv(ENA_URL, sep='\\t')\n",
    "download_table = download_table[download_table['submitted_format']=='FASTQ;FASTQ']\n",
<<<<<<< HEAD
    "# download_table.head()\n",
=======
>>>>>>> beda7fbb5190155ca96a7702217ac28b225ebc1e
    "\n",
    "metadata = pd.read_csv(metadata_URL, encoding=\"ISO-8859-1\", sep='\\t')\n",
    "metadata = metadata[(metadata['#Sequencing_Panel']=='C') & (metadata['Embargo']=='FullyPublic')]\n",
    "metadata = metadata.drop_duplicates(subset=['Region'], keep='last')\n",
    "\n",
    "download_table = download_table[download_table['library_name'].isin([x for x in metadata['Illumina_ID']])]\n",
    "# download_table.head()\n",
    "\n",
    "# [wd] = !pwd\n",
    "for sample_ID in metadata['Illumina_ID']:\n",
    "    !mkdir -p fastq/{sample_ID}\n",
    "    \n",
    "    print(\"Dowloading fastq partial files for sample:\", sample_ID)\n",
    "    [fastq_url] = download_table[download_table['library_name']==sample_ID]['fastq_ftp'].str.split(';').values\n",
    "    [run_accession] = download_table[download_table['library_name']==sample_ID]['run_accession'].values\n",
<<<<<<< HEAD
    "    \n",
=======
    "        \n",
>>>>>>> beda7fbb5190155ca96a7702217ac28b225ebc1e
    "    if os.path.exists('fastq/' + sample_ID + '/' + run_accession + '_1.fastq.gz'):\n",
    "        print(\"__fastq 1 file already present__\")\n",
    "    else:\n",
    "        !wget --quiet -O - '{fastq_url[0]}' | zcat 2>/dev/null | head -n 8000000 - | gzip - > fastq/{sample_ID}/{run_accession}_1.fastq.gz\n",
    "    if os.path.exists('fastq/' + sample_ID + '/' + run_accession + '_2.fastq.gz'):\n",
    "        print(\"__fastq 2 file already present__\")\n",
    "    else:\n",
    "        !wget --quiet -O - '{fastq_url[1]}' | zcat 2>/dev/null | head -n 8000000 - | gzip - > fastq/{sample_ID}/{run_accession}_2.fastq.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MD5 checksum\n",
    "\n",
<<<<<<< HEAD
    "\n",
    "..........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample_ID in metadata['Illumina_ID']:\n",
    "#     !cd fastq/{sample_ID} \n",
    "    \n",
    "#     print(\"MD5 checksum for fastq files of sample:\", sample_ID)    \n",
    "#     md5_1 = download_table[download_table['library_name']==sample_ID]['fastq_md5'].str.split(';').values\n",
    "#     md5_2 = download_table[download_table['library_name']==sample_ID]['fastq_md5'].str.split(';').values\n",
    "    \n",
    "#     # md5 command\n",
    "#     # ..\n",
    "# #     !cd {wd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
    "[MD5](https://en.wikipedia.org/wiki/MD5) is a hash function that produces a 32-character string ([checksum](https://en.wikipedia.org/wiki/Checksum)) for a given file and is widely used to check for data corruption in data files after their transmission or storage. For instance, since the checksum is unique (with very high probability) for every file, if this is the same before and after the downloading of a data file, this means the two files are the same and no data corruption occured during the transfer.\n",
    "\n",
    "When working with relatively big datasets (hundreds-to-thousands of samples, but also smaller numbers), its not rare that some of the downloaded files experienced some sort of small data corruption even after a 'succesfull' exit status and finishing during a wget retrieval (as used above). it is a bit annoying to find out about this issue later on in other stages of the data processing, so it is always much better if one has a quick way to do a checksum test and re-download those data files not passing it. \n",
    "\n",
    "In this case and since we modified the original fastq files from ENA repository by reducing the number of reads in each file, we can no longer use the MD5 checksums pre-computed and provided originally for the complete files. However I have computed them in advanced for these reduced fastq files and here below there is an example on how the test can be done. "
   ]
>>>>>>> beda7fbb5190155ca96a7702217ac28b225ebc1e
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checksum test for sample: LP6005443-DNA_B04\n",
      "[ fastq file 1 ] Succesfull test\n",
      "[ fastq file 2 ] Succesfull test\n",
      "Checksum test for sample: LP6005441-DNA_A08\n",
      "[ fastq file 1 ] Succesfull test\n",
      "[ fastq file 2 ] Succesfull test\n",
      "Checksum test for sample: LP6005441-DNA_B09\n",
      "[ fastq file 1 ] Succesfull test\n",
      "[ fastq file 2 ] Succesfull test\n",
      "Checksum test for sample: LP6005441-DNA_G09\n",
      "[ fastq file 1 ] Succesfull test\n",
      "[ fastq file 2 ] Succesfull test\n",
      "Checksum test for sample: LP6005519-DNA_G02\n",
      "[ fastq file 1 ] Succesfull test\n",
      "[ fastq file 2 ] Succesfull test\n",
      "Checksum test for sample: LP6005442-DNA_B12\n",
      "[ fastq file 1 ] Succesfull test\n",
      "[ fastq file 2 ] Succesfull test\n",
      "Checksum test for sample: LP6005443-DNA_F08\n",
      "[ fastq file 1 ] Succesfull test\n",
      "[ fastq file 2 ] Succesfull test\n"
     ]
    }
   ],
   "source": [
    "md5_checksums = pd.read_csv('md5_checksums', sep='\\t')\n",
    "\n",
    "for sample_ID in metadata['Illumina_ID']:\n",
    "    \n",
    "    print(\"Checksum test for sample:\", sample_ID)\n",
    "    [run_accession] = download_table[download_table['library_name']==sample_ID]['run_accession'].values\n",
    "    \n",
    "    [checksum_1] = !md5sum fastq/{sample_ID}/{run_accession}_1.fastq.gz | cut -d' ' -f1\n",
    "    [expected_checksum_1] = md5_checksums[md5_checksums['Sample_ID']==sample_ID]['fastq_1'].values\n",
    "    [checksum_2] = !md5sum fastq/{sample_ID}/{run_accession}_2.fastq.gz | cut -d' ' -f1\n",
    "    [expected_checksum_2] = md5_checksums[md5_checksums['Sample_ID']==sample_ID]['fastq_2'].values\n",
    "    \n",
    "    if checksum_1 == expected_checksum_1:\n",
    "        print(\"[ fastq file 1 ] Succesfull test\")\n",
    "    else:\n",
    "        print(\"[ fastq file 1 ] checksum test unsuccesfull...\\nRe-dowloading fastq file 1\", )\n",
    "        !wget --quiet -O - '{fastq_url[0]}' | zcat 2>/dev/null | head -n 8000000 - | gzip - > fastq/{sample_ID}/{run_accession}_1.fastq.gz\n",
    "    \n",
    "    if checksum_2 == expected_checksum_2:\n",
    "        print(\"[ fastq file 2 ] Succesfull test\")\n",
    "    else:\n",
    "        print(\"[ fastq file 2 ] checksum test unsuccesfull...\\nRe-dowloading fastq file 1\", )\n",
    "        !wget --quiet -O - '{fastq_url[1]}' | zcat 2>/dev/null | head -n 8000000 - | gzip - > fastq/{sample_ID}/{run_accession}_1.fastq.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fastq Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fastq file quality check for sample: LP6005443-DNA_B04\n",
      "__quality check for fastq file 1 already present__\n",
      "__quality check for fastq file 2 already present__\n",
      "Fastq file quality check for sample: LP6005441-DNA_A08\n",
      "__quality check for fastq file 1 already present__\n",
      "__quality check for fastq file 2 already present__\n",
      "Fastq file quality check for sample: LP6005441-DNA_B09\n",
      "__quality check for fastq file 1 already present__\n",
      "__quality check for fastq file 2 already present__\n",
      "Fastq file quality check for sample: LP6005441-DNA_G09\n",
      "__quality check for fastq file 1 already present__\n",
      "__quality check for fastq file 2 already present__\n",
      "Fastq file quality check for sample: LP6005519-DNA_G02\n",
      "__quality check for fastq file 1 already present__\n",
      "__quality check for fastq file 2 already present__\n",
      "Fastq file quality check for sample: LP6005442-DNA_B12\n",
      "__quality check for fastq file 1 already present__\n",
      "__quality check for fastq file 2 already present__\n",
      "Fastq file quality check for sample: LP6005443-DNA_F08\n",
      "__quality check for fastq file 1 already present__\n",
      "__quality check for fastq file 2 already present__\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"https://htmlpreview.github.io/?https://github.com/JRodrigoF/fastq2VCF/blob/master/fastq/LP6005441-DNA_A08/ERR1419093_1_fastqc.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f3225870310>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sample_ID in metadata['Illumina_ID']:\n",
    "    \n",
    "    print(\"Fastq file quality check for sample:\", sample_ID)\n",
    "    [run_accession] = download_table[download_table['library_name']==sample_ID]['run_accession'].values\n",
    "    \n",
    "    if os.path.exists('fastq/' + sample_ID + '/' + run_accession + '_1_fastqc.zip'):\n",
    "        print(\"__quality check for fastq file 1 already present__\")\n",
    "    else:\n",
    "        !fastqc fastq/{sample_ID}/{run_accession}_1.fastq.gz\n",
    "\n",
    "    if os.path.exists('fastq/' + sample_ID + '/' + run_accession + '_2_fastqc.zip'):\n",
    "        print(\"__quality check for fastq file 2 already present__\")\n",
    "    else:\n",
    "        !fastqc fastq/{sample_ID}/{run_accession}_2.fastq.gz\n",
    "    \n",
    "from IPython.display import IFrame\n",
    "src='https://htmlpreview.github.io/?https://github.com/JRodrigoF/fastq2VCF/blob/master/fastq/LP6005441-DNA_A08/ERR1419093_1_fastqc.html'\n",
    "IFrame(src, width=1000, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
